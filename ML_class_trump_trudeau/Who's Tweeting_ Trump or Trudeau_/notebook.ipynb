{"nbformat":4,"cells":[{"cell_type":"markdown","source":"## 1. Tweet classification: Trump vs. Trudeau\n<p>So you think you can classify text? How about tweets? In this notebook, we'll take a dive into the world of social media text classification by investigating how to properly classify tweets from two prominent North American politicians: Donald Trump and Justin Trudeau.</p>\n<p><img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/4/47/President_Donald_Trump_and_Prime_Minister_Justin_Trudeau_Joint_Press_Conference%2C_February_13%2C_2017.jpg/800px-President_Donald_Trump_and_Prime_Minister_Justin_Trudeau_Joint_Press_Conference%2C_February_13%2C_2017.jpg\" alt=\"Donald Trump and Justin Trudeau shaking hands.\" height=\"50%\" width=\"50%\"></p>\n<p><a href=\"https://commons.wikimedia.org/wiki/File:President_Donald_Trump_and_Prime_Minister_Justin_Trudeau_Joint_Press_Conference,_February_13,_2017.jpg\">Photo Credit: Executive Office of the President of the United States</a></p>\n<p>Tweets pose specific problems to NLP, including the fact they are shorter texts. There are also plenty of platform-specific conventions to give you hassles: mentions, #hashtags, emoji, links and short-hand phrases (ikr?). Can we overcome those challenges and build a useful classifier for these two tweeters? Yes! Let's get started.</p>\n<p>To begin, we will import all the tools we need from scikit-learn. We will need to properly vectorize our data (<code>CountVectorizer</code> and <code>TfidfVectorizer</code>). And we will also want to import some models, including <code>MultinomialNB</code> from the <code>naive_bayes</code> module, <code>LinearSVC</code> from the <code>svm</code> module and <code>PassiveAggressiveClassifier</code> from the <code>linear_model</code> module. Finally, we'll need <code>sklearn.metrics</code> and <code>train_test_split</code> and <code>GridSearchCV</code> from the <code>model_selection</code> module to evaluate and optimize our model.</p>","metadata":{"editable":false,"dc":{"key":"4"},"deletable":false,"run_control":{"frozen":true},"tags":["context"]}},{"cell_type":"markdown","source":"Task 1: Instructions\nImport the tools you'll need from scikit-learn.\n\nImport CountVectorizer and TfidfVectorizer from sklearn.feature_extraction.text.\nImport train_test_split from sklearn.model_selection.\nImport MultinomialNB from sklearn.naive_bayes.\nImport LinearSVC from sklearn.svm.\nImport metrics from sklearn.\nGood to know\nThis project lets you apply the skills taught in Natural Language Processing Fundamentals in Python.\n\nHaving trouble locating where you can import a module from? Take a look at the scikit-learn API documentation, which lists all of the important modules.","metadata":{"dc":{"key":"4"}}},{"outputs":[],"cell_type":"code","execution_count":0,"source":"# Set seed for reproducibility\nimport random; random.seed(53)\n\n# Import all we need from sklearn\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.svm import LinearSVC\nfrom sklearn import metrics","metadata":{"trusted":false,"dc":{"key":"4"},"collapsed":true,"tags":["sample_code"]}},{"cell_type":"markdown","source":"## 2. Transforming our collected data\n<p>To begin, let's start with a corpus of tweets which were collected in November 2017. They are available in CSV format. We'll use a Pandas DataFrame to help import the data and pass it to scikit-learn for further processing.</p>\n<p>Since the data has been collected via the Twitter API and not split into test and training sets, we'll need to do this. Let's use <code>train_test_split()</code> with <code>random_state=53</code> and a test size of 0.33, just as we did in the DataCamp course. This will ensure we have enough test data and we'll get the same results no matter where or when we run this code.</p>","metadata":{"editable":false,"dc":{"key":"11"},"deletable":false,"run_control":{"frozen":true},"tags":["context"]}},{"cell_type":"markdown","source":"Task 2: Instructions\nImport and prepare your data for machine learning.\n\nCreate a new pandas DataFrame with CSV datasets/tweets.csv.\nCreate target labels y equal to the author column of your DataFrame.\nUse train_test_split() with the imported DataFrame's status column as your data and the target (y). Use random_state=53 and test_size=.33.\nRemember to follow conventions of naming your output variables in train_test_split.","metadata":{"dc":{"key":"11"}}},{"outputs":[],"cell_type":"code","execution_count":0,"source":"import pandas as pd\n\n# Load data\ntweet_df = pd.read_csv('datasets/tweets.csv')\n\n# Create target\ny = tweet_df.author\n\n# Split training and testing data\nX_train, X_test, y_train, y_test = train_test_split(tweet_df['status'], y, test_size=0.33, \n                 random_state=53)","metadata":{"trusted":false,"dc":{"key":"11"},"collapsed":true,"tags":["sample_code"]}},{"cell_type":"markdown","source":"## 3. Vectorize the tweets\n<p>We have the training and testing data all set up, but we need to create vectorized representations of the tweets in order to apply machine learning.</p>\n<p>To do so, we will utilize the <code>CountVectorizer</code> and <code>TfidfVectorizer</code> classes which we will first need to fit to the data.</p>\n<p>Once this is complete, we can start modeling with the new vectorized tweets!</p>","metadata":{"editable":false,"dc":{"key":"18"},"deletable":false,"run_control":{"frozen":true},"tags":["context"]}},{"cell_type":"markdown","source":"Task 3: Instructions\nVectorize the data to train a model.\n\nInitialize a CountVectorizer object called count_vectorizer with English stop words removed, a minimum frequency of 0.05, and a maximum frequency of 0.9.\nCreate count_train and count_test variables using fit_transform and transform respectively.\nInitialize a TfidfVectorizer object called tfidf_vectorizer with English stop words removed, a minimum frequency of 0.05, and a maximum frequency of 0.9.\nSet up tfidf_train and tfidf_test variables using fit_transform and transform with the tfidf_vectorizer object.\nHaving trouble remembering how to run fit_transform or transform? Take a look at the CountVectorizer documentation.","metadata":{"dc":{"key":"18"}}},{"outputs":[],"cell_type":"code","execution_count":0,"source":"# Initialize count vectorizer\ncount_vectorizer = CountVectorizer(stop_words='english', \n                                   min_df=0.05, max_df=0.9)\n\n# Create count train and test variables\ncount_train = count_vectorizer.fit_transform(X_train)\ncount_test = count_vectorizer.transform(X_test)\n\n# Initialize tfidf vectorizer\ntfidf_vectorizer = TfidfVectorizer(stop_words='english', \n                                   min_df=0.05, max_df=0.9)\n\n# Create tfidf train and test variables\ntfidf_train = tfidf_vectorizer.fit_transform(X_train)\ntfidf_test = tfidf_vectorizer.transform(X_test)","metadata":{"trusted":false,"dc":{"key":"18"},"collapsed":true,"tags":["sample_code"]}},{"cell_type":"markdown","source":"## 4. Training a multinomial naive Bayes model\n<p>Now that we have the data in vectorized form, we can train the first model. Investigate using the Multinomial Naive Bayes model with both the <code>CountVectorizer</code> and <code>TfidfVectorizer</code> data. Which do will perform better? How come?</p>\n<p>To assess the accuracies, we will print the test sets accuracy scores for both models.</p>","metadata":{"editable":false,"dc":{"key":"25"},"deletable":false,"run_control":{"frozen":true},"tags":["context"]}},{"cell_type":"markdown","source":"Task 4: Instructions\nTrain and test a Bayesian models using the TF-IDF vectors and count vectors to see how they perform.\n\nCreate tfidf_nb, a Multinomial Naive Bayes Classifier with TfidfVectorizer data.\nFit the model and save the test data predictions as tfidf_nb_pred and the accuracy score as tfidf_nb_score.\nCreate count_nb, a Multinomial Naive Bayes Classifier with CountVectorizer data.\nFit the model and save the test predictions as count_nb_pred and the accuracy score as count_nb_score.\nYou can use the metrics.accuracy_score method to return accuracy metrics.","metadata":{"dc":{"key":"25"}}},{"outputs":[],"cell_type":"code","execution_count":0,"source":"tfidf_nb = MultinomialNB()\ntfidf_nb.fit(tfidf_train, y_train)\ntfidf_nb_pred = tfidf_nb.predict(tfidf_test)\ntfidf_nb_score = metrics.accuracy_score(y_test, tfidf_nb_pred)\n\ncount_nb = MultinomialNB()\ncount_nb.fit(count_train, y_train)\ncount_nb_pred = count_nb.predict(count_test)\ncount_nb_score = metrics.accuracy_score(y_test, count_nb_pred)\n\nprint('NaiveBayes Tfidf Score: ', tfidf_nb_score)\nprint('NaiveBayes Count Score: ', count_nb_score)","metadata":{"trusted":false,"dc":{"key":"25"},"collapsed":true,"tags":["sample_code"]}},{"cell_type":"markdown","source":"## 5. Evaluating our model using a confusion matrix\n<p>We see that the TF-IDF model performs better than the count-based approach. Based on what we know from the NLP fundamentals course, why might that be? We know that TF-IDF allows unique tokens to have a greater weight - perhaps tweeters are using specific important words that identify them! Let's continue the investigation.</p>\n<p>For classification tasks, an accuracy score doesn't tell the whole picture. A better evaluation can be made if we look at the confusion matrix, which shows the number correct and incorrect classifications based on each class. We can use the metrics, True Positives, False Positives, False Negatives, and True Negatives, to determine how well the model performed on a given class. How many times was Trump misclassified as Trudeau?</p>","metadata":{"editable":false,"dc":{"key":"32"},"deletable":false,"run_control":{"frozen":true},"tags":["context"]}},{"cell_type":"markdown","source":"Task 5: Instructions\nPlot confusion matrices using the provided helper function and the built-in metrics.confusion_matrix function from scikit-learn.\n\nCreate confusion matrices tfidf_nb_cm and count_nb_cm using the metrics.confusion_matrix function with y_test, and tfidf_nb_pred and count_nb_pred respectively. Labels for both matrices are a list of the names in this order: ['Donald J. Trump', 'Justin Trudeau'].\nPlot tfidf_nb_cm using the plot_confusion_matrix function by passing in the confusion matrix, the list of classes in the correct order, and a title for clarity.\nPlot the count_nb_cm same as above, making sure to also pass in the parameter figure=1 so the first plot is not overwritten.","metadata":{"dc":{"key":"32"}}},{"outputs":[],"cell_type":"code","execution_count":0,"source":"%matplotlib inline\nfrom datasets.helper_functions import plot_confusion_matrix\n\n\ntfidf_nb_cm = metrics.confusion_matrix(y_test, tfidf_nb_pred, labels=['Donald J. Trump', 'Justin Trudeau'])\ncount_nb_cm = metrics.confusion_matrix(y_test, count_nb_pred, labels=['Donald J. Trump', 'Justin Trudeau'])\n\nplot_confusion_matrix(tfidf_nb_cm, classes=['Donald J. Trump', 'Justin Trudeau'], title=\"TF-IDF NB Confusion Matrix\")\n\nplot_confusion_matrix(count_nb_cm, classes=['Donald J. Trump', 'Justin Trudeau'], title=\"Count NB Confusion Matrix\", figure=1)","metadata":{"trusted":false,"dc":{"key":"32"},"collapsed":true,"tags":["sample_code"]}},{"cell_type":"markdown","source":"## 6. Trying out another classifier: Linear SVC\n<p>So the Bayesian model only has one prediction difference between the TF-IDF and count vectorizers -- fairly impressive! Interestingly, there is some confusion when the predicted label is Trump but the actual tweeter is Trudeau. If we were going to use this model, we would want to investigate what tokens are causing the confusion in order to improve the model. </p>\n<p>Now that we've seen what the Bayesian model can do, how about trying a different approach? <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html\">LinearSVC</a> is another popular choice for text classification. Let's see if using it with the TF-IDF vectors improves the accuracy of the classifier!</p>","metadata":{"editable":false,"dc":{"key":"39"},"deletable":false,"run_control":{"frozen":true},"tags":["context"]}},{"cell_type":"markdown","source":"Task 6: Instructions\nCreate, train, and test a LinearSVC model to see how it compares to the Bayesian model.\n\nCreate tfidf_svc, a Linear Support Vector Classifier with TfidfVectorizer data.\nFit the model and save the test data predictions as tfidf_svc_pred and the accuracy score as tfidf_svc_score.\nCreate a confustion matrix, svc_cm, with the metrics.confusion_matrix function, y_test, and tfidf_svc_pred. Again, the labels need to be in order.\nPlot the confusion matrix and pass in the classes as a list in the correct order and title for clarity.\nTo get the accuracy score, use the predicted labels with y_test labels by passing both to the metrics.accuracy_score function. This function will test each prediction and give you an overall accuracy of the predicted labels.","metadata":{"dc":{"key":"39"}}},{"outputs":[],"cell_type":"code","execution_count":0,"source":"tfidf_svc = LinearSVC()\ntfidf_svc.fit(tfidf_train, y_train)\ntfidf_svc_pred = tfidf_svc.predict(tfidf_test)\ntfidf_svc_score = metrics.accuracy_score(y_test, tfidf_svc_pred)\n\nprint(\"LinearSVC Score:   %0.3f\" % tfidf_svc_score)\n\nsvc_cm = metrics.confusion_matrix(y_test, tfidf_svc_pred, labels=['Donald J. Trump', 'Justin Trudeau'])\nplot_confusion_matrix(svc_cm, classes=['Donald J. Trump', 'Justin Trudeau'], title=\"TF-IDF LinearSVC Confusion Matrix\")","metadata":{"trusted":false,"dc":{"key":"39"},"collapsed":true,"tags":["sample_code"]}},{"cell_type":"markdown","source":"## 7. Introspecting our top model\n<p>Wow, the LinearSVC model is even better than the Multinomial Bayesian one. Nice work! Via the confusion matrix we can see that, although there is still some confusion where Trudeau's tweets are classified as Trump's, the False Positive rate is better than the previous model. So, we have a performant model, right? </p>\n<p>We might be able to continue tweaking and improving all of the previous models by learning more about parameter optimization or applying some better preprocessing of the tweets. </p>\n<p>Now let's see what the model has learned. Using the LinearSVC Classifier with two classes (Trump and Trudeau) we can sort the features (tokens), by their weight and see the most important tokens for both Trump and Trudeau. What are the most Trump-like or Trudeau-like words? Did the model learn something useful to distinguish between these two men? </p>","metadata":{"editable":false,"dc":{"key":"46"},"deletable":false,"run_control":{"frozen":true},"tags":["context"]}},{"cell_type":"markdown","source":"Task 7: Instructions\nPlot the features from most Trump-like to most Trudeau-like using plot_and_return_top_features.\n\nImport pprint from module pprint.\nUse plot_and_return_top_features and save the output as top_features.\nPrint top_features to see the tokens and their weights. Analyze the resulting graph. What tokens are most Trump-like? Most Trudeau-like? Do you notice anything that we could have caught in preprocessing?\nMake sure to read the docstring documentation to know what order to pass in the classifier and vectorizer. Remember to use the top performing model!","metadata":{"dc":{"key":"46"}}},{"outputs":[],"cell_type":"code","execution_count":0,"source":"from datasets.helper_functions import plot_and_return_top_features\n\nfrom pprint import pprint\ntop_features = plot_and_return_top_features(tfidf_svc, tfidf_vectorizer)\npprint(top_features)","metadata":{"trusted":false,"dc":{"key":"46"},"collapsed":true,"tags":["sample_code"]}},{"cell_type":"markdown","source":"## 8. Bonus: can you write a Trump or Trudeau tweet?\n<p>So, what did our model learn? It seems like it learned that Trudeau tweets in French!</p>\n<p>I challenge you to write your own tweet using the knowledge gained to trick the model! Use the printed list or plot above to make some inferences about what words will classify your text as Trump or Trudeau. Can you fool the model into thinking you are Trump or Trudeau?</p>\n<p>If you can write French, feel free to make your Trudeau-impersonation tweet in French! As you may have noticed, these French words are common words, or, \"stop words\". You could remove both English and French stop words from the tweets as a preprocessing step, but that might decrease the accuracy of the model because Trudeau is the only French-speaker in the group. If you had a dataset with more than one French speaker, this would be a useful preprocessing step.</p>\n<p>Future work on this dataset could involve:</p>\n<ul>\n<li>Add extra preprocessing (such as removing URLs or French stop words) and see the effects</li>\n<li>Use GridSearchCV to improve both your Bayesian and LinearSVC models by finding the optimal parameters</li>\n<li>Introspect your Bayesian model to determine what words are more Trump- or Trudeau- like</li>\n<li>Add more recent tweets to your dataset using tweepy and retrain</li>\n</ul>\n<p>Good luck writing your impersonation tweets -- feel free to share them on Twitter!</p>","metadata":{"editable":false,"dc":{"key":"53"},"deletable":false,"run_control":{"frozen":true},"tags":["context"]}},{"cell_type":"markdown","source":"Task 8: Instructions\nCreate one tweet to classify as Trump and one tweet to classify as Trudeau. Test them with the model.\n\nWrite a tweet you think will be classified as Trump and save it as trump_tweet.\nWrite a tweet you think will be classified as Trudeau and save it as trudeau_tweet.\nUsing tfidf_vectorizer, transform the two tweets you created and save the transformed tweets as trump_tweet_vectorized and trudeau_tweet_vectorized. Remember, the vectorizer expects a list of strings, so make sure to put your tweet inside a list.\nUsing the tfidf_svc model, predict the label for each vectorized tweet and save the predictions as trump_tweet_pred and trudeau_tweet_pred.\nRemember to use a list when giving the string of the tweet to the vectorizer transform method.","metadata":{"dc":{"key":"53"}}},{"outputs":[],"cell_type":"code","execution_count":0,"source":"# Write two tweets as strings, one which you want to classify as Trump and one as Trudeau\ntrump_tweet = ...\ntrudeau_tweet = ...\n\n# Vectorize each tweet using the TF-IDF vectorizer's transform method\n# Note: `transform` needs the string in a list object (i.e. [trump_tweet])\ntrump_tweet_vectorized = ...\ntrudeau_tweet_vectorized = ...\n\n# Call the predict method on your vectorized tweets\ntrump_tweet_pred = ...\ntrudeau_tweet_pred = ...\n\nprint(\"Predicted Trump tweet\", trump_tweet_pred)\nprint(\"Predicted Trudeau tweet\", trudeau_tweet_pred)","metadata":{"trusted":false,"dc":{"key":"53"},"collapsed":true,"tags":["sample_code"]}}],"nbformat_minor":2,"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"file_extension":".py","pygments_lexer":"ipython3","nbconvert_exporter":"python","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"name":"python","version":"3.5.2"}}}